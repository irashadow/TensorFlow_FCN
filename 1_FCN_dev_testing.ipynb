{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import skimage\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "\n",
    "import os\n",
    "import scipy as scp\n",
    "import scipy.misc\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "#import fcn32_vgg\n",
    "import utils\n",
    "\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "import tensorflow as tf\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "img1 = skimage.io.imread(\"./test_data/tabby_cat.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#with tf.Session() as sess:\n",
    "images = tf.placeholder(\"float\")\n",
    "feed_dict = {images: img1}\n",
    "batch_images = tf.expand_dims(images, 0)\n",
    "\n",
    "#check batch_images's size\n",
    "#temp = sess.run(batch_images, feed_dict = feed_dict)\n",
    "#print(temp.shape)\n",
    "#vgg_fcn = fcn32_vgg.FCN32VGG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "npy file loaded\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import logging\n",
    "from math import ceil\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "VGG_MEAN = [103.939, 116.779, 123.68]\n",
    "\n",
    "class FCN32VGG:\n",
    "    def __init__(self, vgg16_npy_path=None):\n",
    "        if vgg16_npy_path is None:\n",
    "            #path = sys.modules[self.__class__.__module__].__file__\n",
    "            #print path\n",
    "            #path = os.path.abspath(os.path.join(path, os.pardir))\n",
    "            path = '/home/irashadow/python_workspace/TensorFlow_Semantic_Segmentation/tensorflow-fcn'\n",
    "            # print path\n",
    "            path = os.path.join(path, \"vgg16.npy\")\n",
    "            vgg16_npy_path = path\n",
    "            logging.info(\"Load npy file from '%s'.\", vgg16_npy_path)\n",
    "        if not os.path.isfile(vgg16_npy_path):\n",
    "            logging.error((\"File '%s' not found. Download it from \"\n",
    "                           \"https://dl.dropboxusercontent.com/u/\"\n",
    "                           \"50333326/vgg16.npy\"), vgg16_npy_path)\n",
    "            sys.exit(1)\n",
    "\n",
    "        self.data_dict = np.load(vgg16_npy_path, encoding='latin1').item()\n",
    "    \n",
    "        self.wd = 5e-4\n",
    "        print(\"npy file loaded\")\n",
    "        \n",
    "    def build(self, rgb, train=False, num_classes=20, random_init_fc8=False,\n",
    "              debug=False):\n",
    "        \"\"\"\n",
    "        Build the VGG model using loaded weights\n",
    "        Parameters\n",
    "        ----------\n",
    "        rgb: image batch tensor\n",
    "            Image in rgb shap. Scaled to Intervall [0, 255]\n",
    "        train: bool\n",
    "            Whether to build train or inference graph\n",
    "        num_classes: int\n",
    "            How many classes should be predicted (by fc8)\n",
    "        random_init_fc8 : bool\n",
    "            Whether to initialize fc8 layer randomly.\n",
    "            Finetuning is required in this case.\n",
    "        debug: bool\n",
    "            Whether to print additional Debug Information.\n",
    "        \"\"\"\n",
    "        # Convert RGB to BGR\n",
    "\n",
    "        with tf.name_scope('Processing'):\n",
    "\n",
    "            red, green, blue = tf.split(3, 3, rgb)\n",
    "            # assert red.get_shape().as_list()[1:] == [224, 224, 1]\n",
    "            # assert green.get_shape().as_list()[1:] == [224, 224, 1]\n",
    "            # assert blue.get_shape().as_list()[1:] == [224, 224, 1]\n",
    "            bgr = tf.concat(3, [\n",
    "                blue - VGG_MEAN[0],\n",
    "                green - VGG_MEAN[1],\n",
    "                red - VGG_MEAN[2],\n",
    "            ])\n",
    "\n",
    "            if debug:\n",
    "                bgr = tf.Print(bgr, [tf.shape(bgr)],\n",
    "                               message='Shape of input image: ',\n",
    "                               summarize=4, first_n=1)\n",
    "\n",
    "        self.conv1_1 = self._conv_layer(bgr, \"conv1_1\")\n",
    "        self.conv1_2 = self._conv_layer(self.conv1_1, \"conv1_2\")\n",
    "        self.pool1 = self._max_pool(self.conv1_2, 'pool1', debug)\n",
    "\n",
    "        self.conv2_1 = self._conv_layer(self.pool1, \"conv2_1\")\n",
    "        self.conv2_2 = self._conv_layer(self.conv2_1, \"conv2_2\")\n",
    "        self.pool2 = self._max_pool(self.conv2_2, 'pool2', debug)\n",
    "\n",
    "        self.conv3_1 = self._conv_layer(self.pool2, \"conv3_1\")\n",
    "        self.conv3_2 = self._conv_layer(self.conv3_1, \"conv3_2\")\n",
    "        self.conv3_3 = self._conv_layer(self.conv3_2, \"conv3_3\")\n",
    "        self.pool3 = self._max_pool(self.conv3_3, 'pool3', debug)\n",
    "\n",
    "        self.conv4_1 = self._conv_layer(self.pool3, \"conv4_1\")\n",
    "        self.conv4_2 = self._conv_layer(self.conv4_1, \"conv4_2\")\n",
    "        self.conv4_3 = self._conv_layer(self.conv4_2, \"conv4_3\")\n",
    "        self.pool4 = self._max_pool(self.conv4_3, 'pool4', debug)\n",
    "\n",
    "        self.conv5_1 = self._conv_layer(self.pool4, \"conv5_1\")\n",
    "        self.conv5_2 = self._conv_layer(self.conv5_1, \"conv5_2\")\n",
    "        self.conv5_3 = self._conv_layer(self.conv5_2, \"conv5_3\")\n",
    "        self.pool5 = self._max_pool(self.conv5_3, 'pool5', debug)\n",
    "\n",
    "        self.fc6 = self._fc_layer(self.pool5, \"fc6\")\n",
    "\n",
    "        if train:\n",
    "            self.fc6 = tf.nn.dropout(self.fc6, 0.5)\n",
    "\n",
    "        self.fc7 = self._fc_layer(self.fc6, \"fc7\")\n",
    "        if train:\n",
    "            self.fc7 = tf.nn.dropout(self.fc7, 0.5)\n",
    "\n",
    "        if random_init_fc8:\n",
    "            self.score_fr = self._score_layer(self.fc7, \"score_fr\",\n",
    "                                              num_classes)\n",
    "        else:\n",
    "            self.score_fr = self._fc_layer(self.fc7, \"score_fr\",\n",
    "                                           num_classes=num_classes,\n",
    "                                           relu=False)\n",
    "\n",
    "        self.pred = tf.argmax(self.score_fr, dimension=3)\n",
    "\n",
    "        self.upscore = self._upscore_layer(self.score_fr, shape=tf.shape(bgr),\n",
    "                                           num_classes=num_classes,\n",
    "                                           debug=debug,\n",
    "                                           name='up', ksize=64, stride=32)\n",
    "\n",
    "        self.pred_up = tf.argmax(self.upscore, dimension=3)\n",
    "\n",
    "    def _max_pool(self, bottom, name, debug):\n",
    "        pool = tf.nn.max_pool(bottom, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1],\n",
    "                              padding='SAME', name=name)\n",
    "\n",
    "        if debug:\n",
    "            pool = tf.Print(pool, [tf.shape(pool)],\n",
    "                            message='Shape of %s' % name,\n",
    "                            summarize=4, first_n=1)\n",
    "        return pool\n",
    "\n",
    "    def _conv_layer(self, bottom, name):\n",
    "        with tf.variable_scope(name) as scope:\n",
    "            filt = self.get_conv_filter(name)\n",
    "            conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "            conv_biases = self.get_bias(name)\n",
    "            bias = tf.nn.bias_add(conv, conv_biases)\n",
    "\n",
    "            relu = tf.nn.relu(bias)\n",
    "            # Add summary to Tensorboard\n",
    "            _activation_summary(relu)\n",
    "            return relu\n",
    "\n",
    "    def _fc_layer(self, bottom, name, num_classes=None,\n",
    "                  relu=True, debug=False):\n",
    "        with tf.variable_scope(name) as scope:\n",
    "            shape = bottom.get_shape().as_list()\n",
    "\n",
    "            if name == 'fc6':\n",
    "                filt = self.get_fc_weight_reshape(name, [7, 7, 512, 4096])\n",
    "            elif name == 'score_fr':\n",
    "                name = 'fc8'  # Name of score_fr layer in VGG Model\n",
    "                filt = self.get_fc_weight_reshape(name, [1, 1, 4096, 1000],\n",
    "                                                  num_classes=num_classes)\n",
    "            else:\n",
    "                filt = self.get_fc_weight_reshape(name, [1, 1, 4096, 4096])\n",
    "            conv = tf.nn.conv2d(bottom, filt, [1, 1, 1, 1], padding='SAME')\n",
    "            conv_biases = self.get_bias(name, num_classes=num_classes)\n",
    "            bias = tf.nn.bias_add(conv, conv_biases)\n",
    "\n",
    "            if relu:\n",
    "                bias = tf.nn.relu(bias)\n",
    "            _activation_summary(bias)\n",
    "\n",
    "            if debug:\n",
    "                bias = tf.Print(bias, [tf.shape(bias)],\n",
    "                                message='Shape of %s' % name,\n",
    "                                summarize=4, first_n=1)\n",
    "            return bias\n",
    "\n",
    "    def _score_layer(self, bottom, name, num_classes):\n",
    "        with tf.variable_scope(name) as scope:\n",
    "            # get number of input channels\n",
    "            in_features = bottom.get_shape()[3].value\n",
    "            shape = [1, 1, in_features, num_classes]\n",
    "            # He initialization Sheme\n",
    "            num_input = in_features\n",
    "            stddev = (2 / num_input)**0.5\n",
    "            # Apply convolution\n",
    "            w_decay = self.wd\n",
    "            weights = self._variable_with_weight_decay(shape, stddev, w_decay)\n",
    "            conv = tf.nn.conv2d(bottom, weights, [1, 1, 1, 1], padding='SAME')\n",
    "            # Apply bias\n",
    "            conv_biases = self._bias_variable([num_classes], constant=0.0)\n",
    "            bias = tf.nn.bias_add(conv, conv_biases)\n",
    "\n",
    "            _activation_summary(bias)\n",
    "\n",
    "            return bias\n",
    "\n",
    "    def _upscore_layer(self, bottom, shape,\n",
    "                       num_classes, name, debug,\n",
    "                       ksize=4, stride=2):\n",
    "        strides = [1, stride, stride, 1]\n",
    "        with tf.variable_scope(name):\n",
    "            in_features = bottom.get_shape()[3].value\n",
    "\n",
    "            if shape is None:\n",
    "                # Compute shape out of Bottom\n",
    "                in_shape = tf.shape(bottom)\n",
    "\n",
    "                h = ((in_shape[1] - 1) * stride) + 1\n",
    "                w = ((in_shape[2] - 1) * stride) + 1\n",
    "                new_shape = [in_shape[0], h, w, num_classes]\n",
    "            else:\n",
    "                new_shape = [shape[0], shape[1], shape[2], num_classes]\n",
    "            output_shape = tf.pack(new_shape)\n",
    "\n",
    "            logging.debug(\"Layer: %s, Fan-in: %d\" % (name, in_features))\n",
    "            f_shape = [ksize, ksize, num_classes, in_features]\n",
    "\n",
    "            # create\n",
    "            num_input = ksize * ksize * in_features / stride\n",
    "            stddev = (2 / num_input)**0.5\n",
    "\n",
    "            weights = self.get_deconv_filter(f_shape)\n",
    "            deconv = tf.nn.conv2d_transpose(bottom, weights, output_shape,\n",
    "                                            strides=strides, padding='SAME')\n",
    "\n",
    "            if debug:\n",
    "                deconv = tf.Print(deconv, [tf.shape(deconv)],\n",
    "                                  message='Shape of %s' % name,\n",
    "                                  summarize=4, first_n=1)\n",
    "\n",
    "        _activation_summary(deconv)\n",
    "        return deconv\n",
    "\n",
    "    def get_deconv_filter(self, f_shape):\n",
    "        width = f_shape[0]\n",
    "        heigh = f_shape[0]\n",
    "        f = ceil(width/2.0)\n",
    "        c = (2 * f - 1 - f % 2) / (2.0 * f)\n",
    "        bilinear = np.zeros([f_shape[0], f_shape[1]])\n",
    "        for x in range(width):\n",
    "            for y in range(heigh):\n",
    "                value = (1 - abs(x / f - c)) * (1 - abs(y / f - c))\n",
    "                bilinear[x, y] = value\n",
    "        weights = np.zeros(f_shape)\n",
    "        for i in range(f_shape[2]):\n",
    "            weights[:, :, i, i] = bilinear\n",
    "\n",
    "        init = tf.constant_initializer(value=weights,\n",
    "                                       dtype=tf.float32)\n",
    "        return tf.get_variable(name=\"up_filter\", initializer=init,\n",
    "                               shape=weights.shape)\n",
    "\n",
    "    def get_conv_filter(self, name):\n",
    "        init = tf.constant_initializer(value=self.data_dict[name][0],\n",
    "                                       dtype=tf.float32)\n",
    "        shape = self.data_dict[name][0].shape\n",
    "        print('Layer name: %s' % name)\n",
    "        print('Layer shape: %s' % str(shape))\n",
    "        var = tf.get_variable(name=\"filter\", initializer=init, shape=shape)\n",
    "        if not tf.get_variable_scope().reuse:\n",
    "            weight_decay = tf.mul(tf.nn.l2_loss(var), self.wd,\n",
    "                                  name='weight_loss')\n",
    "            tf.add_to_collection('losses', weight_decay)\n",
    "        return var\n",
    "\n",
    "    def get_bias(self, name, num_classes=None):\n",
    "        bias_wights = self.data_dict[name][1]\n",
    "        shape = self.data_dict[name][1].shape\n",
    "        if name == 'fc8':\n",
    "            bias_wights = self._bias_reshape(bias_wights, shape[0],\n",
    "                                             num_classes)\n",
    "            shape = [num_classes]\n",
    "        init = tf.constant_initializer(value=bias_wights,\n",
    "                                       dtype=tf.float32)\n",
    "        return tf.get_variable(name=\"biases\", initializer=init, shape=shape)\n",
    "\n",
    "    def get_fc_weight(self, name):\n",
    "        init = tf.constant_initializer(value=self.data_dict[name][0],\n",
    "                                       dtype=tf.float32)\n",
    "        shape = self.data_dict[name][0].shape\n",
    "        var = tf.get_variable(name=\"weights\", initializer=init, shape=shape)\n",
    "        if not tf.get_variable_scope().reuse:\n",
    "            weight_decay = tf.mul(tf.nn.l2_loss(var), self.wd,\n",
    "                                  name='weight_loss')\n",
    "            tf.add_to_collection('losses', weight_decay)\n",
    "        return var\n",
    "\n",
    "    def _bias_reshape(self, bweight, num_orig, num_new):\n",
    "        \"\"\" Build bias weights for filter produces with `_summary_reshape`\n",
    "\n",
    "        \"\"\"\n",
    "        n_averaged_elements = num_orig//num_new\n",
    "        avg_bweight = np.zeros(num_new)\n",
    "        for i in range(0, num_orig, n_averaged_elements):\n",
    "            start_idx = i\n",
    "            end_idx = start_idx + n_averaged_elements\n",
    "            avg_idx = start_idx//n_averaged_elements\n",
    "            if avg_idx == num_new:\n",
    "                break\n",
    "            avg_bweight[avg_idx] = np.mean(bweight[start_idx:end_idx])\n",
    "        return avg_bweight\n",
    "\n",
    "    def _summary_reshape(self, fweight, shape, num_new):\n",
    "        \"\"\" Produce weights for a reduced fully-connected layer.\n",
    "\n",
    "        FC8 of VGG produces 1000 classes. Most semantic segmentation\n",
    "        task require much less classes. This reshapes the original weights\n",
    "        to be used in a fully-convolutional layer which produces num_new\n",
    "        classes. To archive this the average (mean) of n adjanced classes is\n",
    "        taken.\n",
    "\n",
    "        Consider reordering fweight, to perserve semantic meaning of the\n",
    "        weights.\n",
    "\n",
    "        Args:\n",
    "          fweight: original weights\n",
    "          shape: shape of the desired fully-convolutional layer\n",
    "          num_new: number of new classes\n",
    "\n",
    "\n",
    "        Returns:\n",
    "          Filter weights for `num_new` classes.\n",
    "        \"\"\"\n",
    "        num_orig = shape[3]\n",
    "        shape[3] = num_new\n",
    "        assert(num_new < num_orig)\n",
    "        n_averaged_elements = num_orig//num_new\n",
    "        avg_fweight = np.zeros(shape)\n",
    "        for i in range(0, num_orig, n_averaged_elements):\n",
    "            start_idx = i\n",
    "            end_idx = start_idx + n_averaged_elements\n",
    "            avg_idx = start_idx//n_averaged_elements\n",
    "            if avg_idx == num_new:\n",
    "                break\n",
    "            avg_fweight[:, :, :, avg_idx] = np.mean(\n",
    "                fweight[:, :, :, start_idx:end_idx], axis=3)\n",
    "        return avg_fweight\n",
    "\n",
    "    def _variable_with_weight_decay(self, shape, stddev, wd):\n",
    "        \"\"\"Helper to create an initialized Variable with weight decay.\n",
    "\n",
    "        Note that the Variable is initialized with a truncated normal\n",
    "        distribution.\n",
    "        A weight decay is added only if one is specified.\n",
    "\n",
    "        Args:\n",
    "          name: name of the variable\n",
    "          shape: list of ints\n",
    "          stddev: standard deviation of a truncated Gaussian\n",
    "          wd: add L2Loss weight decay multiplied by this float. If None, weight\n",
    "              decay is not added for this Variable.\n",
    "\n",
    "        Returns:\n",
    "          Variable Tensor\n",
    "        \"\"\"\n",
    "\n",
    "        initializer = tf.truncated_normal_initializer(stddev=stddev)\n",
    "        var = tf.get_variable('weights', shape=shape,\n",
    "                              initializer=initializer)\n",
    "\n",
    "        if wd and (not tf.get_variable_scope().reuse):\n",
    "            weight_decay = tf.mul(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "            tf.add_to_collection('losses', weight_decay)\n",
    "        return var\n",
    "\n",
    "    def _bias_variable(self, shape, constant=0.0):\n",
    "        initializer = tf.constant_initializer(constant)\n",
    "        return tf.get_variable(name='biases', shape=shape,\n",
    "                               initializer=initializer)\n",
    "\n",
    "    def get_fc_weight_reshape(self, name, shape, num_classes=None):\n",
    "        print('Layer name: %s' % name)\n",
    "        print('Layer shape: %s' % shape)\n",
    "        weights = self.data_dict[name][0]\n",
    "        weights = weights.reshape(shape)\n",
    "        if num_classes is not None:\n",
    "            weights = self._summary_reshape(weights, shape,\n",
    "                                            num_new=num_classes)\n",
    "        init = tf.constant_initializer(value=weights,\n",
    "                                       dtype=tf.float32)\n",
    "        return tf.get_variable(name=\"weights\", initializer=init, shape=shape)\n",
    "\n",
    "\n",
    "def _activation_summary(x):\n",
    "    \"\"\"Helper to create summaries for activations.\n",
    "\n",
    "    Creates a summary that provides a histogram of activations.\n",
    "    Creates a summary that measure the sparsity of activations.\n",
    "\n",
    "    Args:\n",
    "      x: Tensor\n",
    "    Returns:\n",
    "      nothing\n",
    "    \"\"\"\n",
    "    # Remove 'tower_[0-9]/' from the name in case this is a multi-GPU training\n",
    "    # session. This helps the clarity of presentation on tensorboard.\n",
    "    tensor_name = x.op.name\n",
    "    # tensor_name = re.sub('%s_[0-9]*/' % TOWER_NAME, '', x.op.name)\n",
    "    tf.histogram_summary(tensor_name + '/activations', x)\n",
    "    tf.scalar_summary(tensor_name + '/sparsity', tf.nn.zero_fraction(x))\n",
    "    \n",
    "\n",
    "\n",
    "vgg_fcn = FCN32VGG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer name: conv1_1\n",
      "Layer shape: (3, 3, 3, 64)\n",
      "Layer name: conv1_2\n",
      "Layer shape: (3, 3, 64, 64)\n",
      "Layer name: conv2_1\n",
      "Layer shape: (3, 3, 64, 128)\n",
      "Layer name: conv2_2\n",
      "Layer shape: (3, 3, 128, 128)\n",
      "Layer name: conv3_1\n",
      "Layer shape: (3, 3, 128, 256)\n",
      "Layer name: conv3_2\n",
      "Layer shape: (3, 3, 256, 256)\n",
      "Layer name: conv3_3\n",
      "Layer shape: (3, 3, 256, 256)\n",
      "Layer name: conv4_1\n",
      "Layer shape: (3, 3, 256, 512)\n",
      "Layer name: conv4_2\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "Layer name: conv4_3\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "Layer name: conv5_1\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "Layer name: conv5_2\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "Layer name: conv5_3\n",
      "Layer shape: (3, 3, 512, 512)\n",
      "Layer name: fc6\n",
      "Layer shape: [7, 7, 512, 4096]\n",
      "Layer name: fc7\n",
      "Layer shape: [1, 1, 4096, 4096]\n",
      "Layer name: fc8\n",
      "Layer shape: [1, 1, 4096, 1000]\n"
     ]
    }
   ],
   "source": [
    "with tf.name_scope(\"content_vgg\"):\n",
    "    vgg_fcn.build(batch_images, debug=True)\n",
    "    #num_classes = 20\n",
    "    #vgg_fcn.build(images, train=True, num_classes=num_classes, random_init_fc8=True)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished building Network.\n",
      "Running the Network\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "\n",
    "print('Finished building Network.')\n",
    "\n",
    "init = tf.initialize_all_variables()\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "print('Running the Network')\n",
    "tensors = [vgg_fcn.pred, vgg_fcn.pred_up]\n",
    "down, up = sess.run(tensors, feed_dict=feed_dict)\n",
    "\n",
    "down_color = utils.color_image(down[0])\n",
    "up_color = utils.color_image(up[0])\n",
    "\n",
    "scp.misc.imsave('fcn32_downsampled.png', down_color)\n",
    "scp.misc.imsave('fcn32_upsampled.png', up_color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
